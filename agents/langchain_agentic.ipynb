{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d397b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class TaggingConfig:\n",
    "    max_tags: int = 3\n",
    "    min_confidence: float = 0.7\n",
    "    use_cache: bool = True\n",
    "    max_tokens_per_request: int = 100\n",
    "\n",
    "class MinimalPromptManager:\n",
    "    \"\"\"Managers prompts with token efficiency\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "        self.system_prompt = \"Tag text. Output: JSON with tags and confidence\"\n",
    "\n",
    "    def get_tagging_prompt(self, text:str) -> str:\n",
    "        \"\"\"Ultra-minimal prompt construction\"\"\"\n",
    "\n",
    "        # Cache prompts for similar texts\n",
    "        text_key = text[:50]  # Use beginning as cache key\n",
    "\n",
    "        if text_key in self.cache:\n",
    "            return f\"Tag like before: {text[:100]}\"\n",
    "\n",
    "        return f\"{self.system_prompt}\\nText: {text[:200]}\"\n",
    "\n",
    "\n",
    "class AutoTaggingAgent:\n",
    "    \"\"\"Efficient tagging agent with minimal API calls\"\"\"\n",
    "\n",
    "    def __init__(self, config: Optional[TaggingConfig] = None):\n",
    "        self.config = config or TaggingConfig()\n",
    "        self.prompt_manager = MinimalPromptManager()\n",
    "        self.tag_cache = {}\n",
    "\n",
    "        self.common_tags = {\n",
    "            'technology': ['ai', 'machine learning', 'programming', 'software'],\n",
    "            'business': ['startup', 'finance', 'marketing', 'management'],\n",
    "            'science': ['research', 'data', 'analysis', 'experiment'],\n",
    "            'general': ['news', 'update', 'guide', 'tutorial']\n",
    "        }\n",
    "\n",
    "    def extract_tags(self, text: str) -> List[Dict[str, float]]:\n",
    "\n",
    "        local_tags = self._extract_local_tags(text)\n",
    "        if len(local_tags) >= self.config.max_tags:\n",
    "            return local_tags[:self.config.max_tags]\n",
    "\n",
    "        \n",
    "        ai_tags = self._extract_ai_tags(text, existing_tags=local_tags)\n",
    "        all_tags = self._merge_tags(local_tags + ai_tags)\n",
    "\n",
    "        return all_tags[:self.config.max_tags]\n",
    "\n",
    "    \n",
    "    def _extract_local_tags(self, text: str) -> List[Dict[str, float]]:\n",
    "            \"\"\"Extract tags using local rules (no API calls)\"\"\"\n",
    "            tags = []\n",
    "            text_lower = text.lower()\n",
    "            \n",
    "            # Rule-based extraction\n",
    "            for category, keywords in self.common_tags.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in text_lower:\n",
    "                        # Simple confidence based on frequency and position\n",
    "                        confidence = min(0.9, 0.3 + text_lower.count(keyword) * 0.1)\n",
    "                        if confidence >= self.config.min_confidence:\n",
    "                            tags.append({\"tag\": keyword, \"confidence\": round(confidence, 2)})\n",
    "            \n",
    "            # Extract hashtags if present\n",
    "            hashtags = re.findall(r'#(\\w+)', text)\n",
    "            for tag in hashtags[:3]:  # Limit hashtags\n",
    "                tags.append({\"tag\": tag.lower(), \"confidence\": 0.85})\n",
    "            \n",
    "            return sorted(tags, key=lambda x: x[\"confidence\"], reverse=True)\n",
    "        \n",
    "    def _extract_ai_tags(self, text: str, existing_tags: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Use AI with minimal prompt for remaining tags\n",
    "        Simulating GPT-5 Nano call with minimal token usage\n",
    "        \"\"\"\n",
    "        # Construct minimal prompt\n",
    "        prompt = self.prompt_manager.get_tagging_prompt(text)\n",
    "        \n",
    "        # Simulated AI response (in real use, call API with minimal tokens)\n",
    "        # Format: JSON only, no explanations\n",
    "        existing_tag_names = [t[\"tag\"] for t in existing_tags]\n",
    "        remaining_slots = self.config.max_tags - len(existing_tags)\n",
    "        \n",
    "        if remaining_slots <= 0:\n",
    "            return []\n",
    "        \n",
    "        # Simulated efficient AI call\n",
    "        # In reality, you'd call: response = openai_minimal_call(prompt)\n",
    "        simulated_response = {\n",
    "            \"tags\": [\n",
    "                {\"tag\": \"artificial intelligence\", \"confidence\": 0.92},\n",
    "                {\"tag\": \"automation\", \"confidence\": 0.88}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return simulated_response[\"tags\"][:remaining_slots]\n",
    "    \n",
    "    def _merge_tags(self, tags: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Merge similar tags and deduplicate\"\"\"\n",
    "        merged = {}\n",
    "        for tag_info in tags:\n",
    "            tag_name = tag_info[\"tag\"]\n",
    "            confidence = tag_info[\"confidence\"]\n",
    "            \n",
    "            if tag_name not in merged or confidence > merged[tag_name]:\n",
    "                merged[tag_name] = confidence\n",
    "        \n",
    "        # Convert back to list and sort\n",
    "        result = [{\"tag\": k, \"confidence\": v} for k, v in merged.items()]\n",
    "        return sorted(result, key=lambda x: x[\"confidence\"], reverse=True)\n",
    "    \n",
    "    def batch_tag(self, texts: List[str]) -> List[List[Dict]]:\n",
    "        \"\"\"Process multiple texts efficiently\"\"\"\n",
    "        return [self.extract_tags(text) for text in texts]\n",
    "    \n",
    "    def get_tag_summary(self, tags: List[Dict]) -> Dict:\n",
    "        \"\"\"Create summary statistics\"\"\"\n",
    "        tag_names = [t[\"tag\"] for t in tags]\n",
    "        return {\n",
    "            \"total_tags\": len(tags),\n",
    "            \"top_tag\": tags[0][\"tag\"] if tags else None,\n",
    "            \"avg_confidence\": sum(t[\"confidence\"] for t in tags) / len(tags) if tags else 0,\n",
    "            \"tag_frequency\": dict(Counter(tag_names))\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52104f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Tagging Agent Demonstration\n",
      "==================================================\n",
      "\n",
      "Text 1: AI and machine learning are revolutionizing healthcare with new diagnostic tools. #AI #HealthTech...\n",
      "Tags extracted: 4\n",
      "  - artificial intelligence (0.92)\n",
      "  - automation (0.88)\n",
      "  - ai (0.85)\n",
      "  - healthtech (0.85)\n",
      "Summary: {'total_tags': 4, 'top_tag': 'artificial intelligence', 'avg_confidence': 0.875, 'tag_frequency': {'artificial intelligence': 1, 'automation': 1, 'ai': 1, 'healthtech': 1}}\n",
      "\n",
      "Text 2: Startup funding reached new heights in Q3 with blockchain companies leading the charge....\n",
      "Tags extracted: 2\n",
      "  - artificial intelligence (0.92)\n",
      "  - automation (0.88)\n",
      "Summary: {'total_tags': 2, 'top_tag': 'artificial intelligence', 'avg_confidence': 0.9, 'tag_frequency': {'artificial intelligence': 1, 'automation': 1}}\n",
      "\n",
      "Text 3: Climate change research shows alarming trends in polar ice melt rates....\n",
      "Tags extracted: 2\n",
      "  - artificial intelligence (0.92)\n",
      "  - automation (0.88)\n",
      "Summary: {'total_tags': 2, 'top_tag': 'artificial intelligence', 'avg_confidence': 0.9, 'tag_frequency': {'artificial intelligence': 1, 'automation': 1}}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Usage Example\n",
    "def demonstrate_agent():\n",
    "    \"\"\"Showcase the agent's capabilities\"\"\"\n",
    "    \n",
    "    # Initialize agent with efficient configuration\n",
    "    config = TaggingConfig(\n",
    "        max_tags=5,\n",
    "        min_confidence=0.6,\n",
    "        max_tokens_per_request=150\n",
    "    )\n",
    "    \n",
    "    agent = AutoTaggingAgent(config)\n",
    "    \n",
    "    # Sample texts\n",
    "    sample_texts = [\n",
    "        \"AI and machine learning are revolutionizing healthcare with new diagnostic tools. #AI #HealthTech\",\n",
    "        \"Startup funding reached new heights in Q3 with blockchain companies leading the charge.\",\n",
    "        \"Climate change research shows alarming trends in polar ice melt rates.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Auto-Tagging Agent Demonstration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, text in enumerate(sample_texts, 1):\n",
    "        print(f\"\\nText {i}: {text[:100]}...\")\n",
    "        tags = agent.extract_tags(text)\n",
    "        summary = agent.get_tag_summary(tags)\n",
    "        \n",
    "        print(f\"Tags extracted: {len(tags)}\")\n",
    "        for tag in tags:\n",
    "            print(f\"  - {tag['tag']} ({tag['confidence']})\")\n",
    "        \n",
    "        print(f\"Summary: {summary}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "demonstrate_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5503d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
